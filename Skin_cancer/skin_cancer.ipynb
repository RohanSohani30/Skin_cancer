{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RohanSohani30/projects/blob/main/Skin_cancer/skin_cancer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "daac8259",
      "metadata": {
        "id": "daac8259"
      },
      "source": [
        "# Reading of datasets"
      ]
    },
    {
      "cell_type": "raw",
      "id": "77a8bc9c",
      "metadata": {
        "id": "77a8bc9c"
      },
      "source": [
        "### Business Case: Build machine learning model to classify skin cancer images\n",
        "\n",
        "#####cancer types:\n",
        "\n",
        "\n",
        "*   Actinic keratoses and intraepithelial carcinoma / Bowen's disease (akiec)\n",
        "*   basal cell carcinoma (bcc)\n",
        "*   benign keratosis-like lesions (solar lentigines / seborrheic keratoses and lichen-planus like keratoses, bkl)\n",
        "*   dermatofibroma (df)\n",
        "*   melanoma (mel)\n",
        "*   melanocytic nevi (nv)\n",
        "*   vascular lesions (angiomas, angiokeratomas, pyogenic granulomas and hemorrhage, vasc)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Here we are using CNN "
      ],
      "metadata": {
        "id": "KY8hGzwOC2kl"
      },
      "id": "KY8hGzwOC2kl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f21e658",
      "metadata": {
        "id": "2f21e658"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09654a84",
      "metadata": {
        "id": "09654a84"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64 # number of datapoints per obsevation in new dataset\n",
        "IMAGE_SIZE1 = 600 # pixl size of images from raw data\n",
        "IMAGE_SIZE2=450\n",
        "CHANNELS=3 # RGB channel\n",
        "EPOCHS=50 # number of epochs for NN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd4f8c39",
      "metadata": {
        "id": "cd4f8c39"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3669c027",
      "metadata": {
        "id": "3669c027",
        "outputId": "c4363385-68c2-4c11-dad0-be1ac3057f25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 10015 files belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "dataset=tf.keras.utils.image_dataset_from_directory(\"destination_folder\",\n",
        "    seed=123,\n",
        "    shuffle=True,\n",
        "    #image_size=(IMAGE_SIZE1,IMAGE_SIZE2),\n",
        "    batch_size=BATCH_SIZE) # this is new dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d93e7394",
      "metadata": {
        "id": "d93e7394",
        "outputId": "468ba84f-621d-49f6-8d90-55718f46bf7c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.dataset_ops.BatchDataset"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "362da8a7",
      "metadata": {
        "id": "362da8a7",
        "outputId": "163c161a-73d8-4de7-a2d9-54070fddf4c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class_names=dataset.class_names # Target variable\n",
        "class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c17b52d8",
      "metadata": {
        "id": "c17b52d8",
        "outputId": "578e7e9f-8cbb-486a-b959-aa60cf2390e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "157"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "d_pt=len(dataset) \n",
        "d_pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d028535c",
      "metadata": {
        "scrolled": true,
        "id": "d028535c",
        "outputId": "92647ad7-f244-458f-98d1-8f8254cf57d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10048"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "157*64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f8e44a0",
      "metadata": {
        "id": "1f8e44a0"
      },
      "outputs": [],
      "source": [
        "#Every Element in dataset is Batch of 32 images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8032d961",
      "metadata": {
        "id": "8032d961",
        "outputId": "cc4d9f1c-3b63-4f91-9960-e9bad7b35af3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<TakeDataset element_spec=(TensorSpec(shape=(None, 600, 450, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_ds=dataset.take(int(d_pt*0.8))\n",
        "train_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0e39ae0",
      "metadata": {
        "id": "e0e39ae0",
        "outputId": "af3ef2ab-a231-4f82-b291-cafbec6a92a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "125"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2f3576a",
      "metadata": {
        "id": "c2f3576a"
      },
      "outputs": [],
      "source": [
        "# took250 obsevations from new dataset as training data i.e 250*32 just like slicing operation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a31d8c8",
      "metadata": {
        "id": "0a31d8c8"
      },
      "outputs": [],
      "source": [
        "test=dataset.skip(125)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "706cf1ff",
      "metadata": {
        "id": "706cf1ff",
        "outputId": "029a1fdd-d5a7-4340-a56a-d116b5a5aed7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05497df9",
      "metadata": {
        "id": "05497df9"
      },
      "outputs": [],
      "source": [
        "# skipped first 250 observation for test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a501850",
      "metadata": {
        "id": "3a501850",
        "outputId": "839c7820-86b9-4e60-d711-7fe9e6f08539"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "16.0"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "32/2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcc51d49",
      "metadata": {
        "id": "bcc51d49",
        "outputId": "b0369773-90a6-40d6-d387-592041751079"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_ds=test.take(16) # validation data is used for validation after evry epoch\n",
        "test_ds=test.skip(16) # test data is used after all epochs are done for model testing\n",
        "len(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d666fc1",
      "metadata": {
        "id": "5d666fc1"
      },
      "outputs": [],
      "source": [
        "# test data is divided into validation data and test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "927610f8",
      "metadata": {
        "id": "927610f8"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import models, layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa01d6b9",
      "metadata": {
        "id": "fa01d6b9"
      },
      "outputs": [],
      "source": [
        "# Resizing and rescaling of input images\n",
        "resize_and_rescale = tf.keras.Sequential([\n",
        "  layers.experimental.preprocessing.Resizing(256, 256),\n",
        "  layers.experimental.preprocessing.Rescaling(1./255),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a9f76e3",
      "metadata": {
        "id": "9a9f76e3"
      },
      "outputs": [],
      "source": [
        "# data augmentation of input images with flips and rotation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df8a7ba3",
      "metadata": {
        "id": "df8a7ba3"
      },
      "outputs": [],
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "  layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dda8824",
      "metadata": {
        "id": "6dda8824"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.map(\n",
        "    lambda x, y: (data_augmentation(x, training=True), y)\n",
        ").prefetch(buffer_size=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e0c2997",
      "metadata": {
        "id": "4e0c2997"
      },
      "outputs": [],
      "source": [
        "# Model Building\n",
        "#convolution layer=> flattend layer => dense layer "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a99c641",
      "metadata": {
        "id": "3a99c641"
      },
      "outputs": [],
      "source": [
        "input_shape = (BATCH_SIZE, IMAGE_SIZE1, IMAGE_SIZE2, CHANNELS)\n",
        "n_classes = 7\n",
        "\n",
        "model = models.Sequential([\n",
        "    resize_and_rescale,\n",
        "    layers.Conv2D(120, kernel_size = (3,3), activation='relu', input_shape=input_shape),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(n_classes, activation='softmax'),\n",
        "])\n",
        "\n",
        "model.build(input_shape=input_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4c4494d",
      "metadata": {
        "id": "a4c4494d",
        "outputId": "765a014e-b699-4d82-f8c5-719cbedb5f46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential_4 (Sequential)   (64, 256, 256, 3)         0         \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (64, 254, 254, 120)       3360      \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (64, 127, 127, 120)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (64, 125, 125, 64)        69184     \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  (64, 62, 62, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (64, 60, 60, 64)          36928     \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  (64, 30, 30, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (64, 28, 28, 64)          36928     \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPoolin  (64, 14, 14, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (64, 12, 12, 64)          36928     \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPoolin  (64, 6, 6, 64)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (64, 4, 4, 64)            36928     \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPoolin  (64, 2, 2, 64)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (64, 256)                 0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (64, 64)                  16448     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (64, 7)                   455       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 237,159\n",
            "Trainable params: 237,159\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2587b73",
      "metadata": {
        "id": "b2587b73"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1177a1d",
      "metadata": {
        "id": "f1177a1d"
      },
      "outputs": [],
      "source": [
        "# for cpu runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7261d39a",
      "metadata": {
        "id": "7261d39a"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "test_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00b6162f",
      "metadata": {
        "id": "00b6162f",
        "outputId": "ab7a9e5b-61d1-4daf-8b57-b7e6b17cf00b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "157/157 [==============================] - 2155s 9s/step - loss: 1.0587 - accuracy: 0.6667\n",
            "Epoch 2/5\n",
            "157/157 [==============================] - 1491s 9s/step - loss: 0.9446 - accuracy: 0.6704\n",
            "Epoch 3/5\n",
            "157/157 [==============================] - 1471s 9s/step - loss: 0.9015 - accuracy: 0.6793\n",
            "Epoch 4/5\n",
            "157/157 [==============================] - 1305s 8s/step - loss: 0.8400 - accuracy: 0.6970\n",
            "Epoch 5/5\n",
            "157/157 [==============================] - 1334s 9s/step - loss: 0.8268 - accuracy: 0.6981\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_data=val_ds,\n",
        "    verbose=1,\n",
        "    epochs=5,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cd86bac",
      "metadata": {
        "id": "2cd86bac",
        "outputId": "71d9306d-1f52-4e16-a495-3bd8311bbaf8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.dataset_ops.PrefetchDataset"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6d5c752",
      "metadata": {
        "scrolled": true,
        "id": "f6d5c752",
        "outputId": "304ddaf0-f753-4e70-ae1b-994e354f521e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 73s 2s/step - loss: 1.9232 - accuracy: 0.6428\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.9232177734375, 0.6427850723266602]"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4380ec1a",
      "metadata": {
        "id": "4380ec1a",
        "outputId": "a967c684-a960-45cc-d952-50adac9bd5cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['bkl', 'nv', 'df', 'mel', 'vasc', 'bcc', 'akiec'], dtype=object)"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        " meta.dx.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1077c9cf",
      "metadata": {
        "id": "1077c9cf"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "skin_cancer.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}